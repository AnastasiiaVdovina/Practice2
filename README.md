# Практична робота №2
Темою практичної роботи №2 були сегменти пам'яті в UNIX-подібних ОС.
## Завдання 1
### Умова
Напишіть програму для визначення моменту, коли time_t
закінчиться.Дослідіть, які зміни відбуваються в залежності від 32- та
64-бітної архітектури. Дослідіть сегменти виконуваного файлу.
### Рішення
Я написала [код](https://github.com/AnastasiiaVdovina/Practice2/blob/main/task1.c), який визначає тип розрядності системи, і в залежності від цього виводить максимальне значення time_t для поточної конфігурації системи. 
Для 32-бітних систем існує так звана "пролбема 2038"([year 2038 problem](https://en.wikipedia.org/wiki/Year_2038_problem)): для 32-біних систем time_t закінчується після 19 січня 2038 року.
В мене 64-бітна система, а отже, time_t в мене закінчиться не скоро, як показав експеримент. Якщо використовувати для визначення останньої дати time_t для 64-бітної системи такий же метод, як і для 32-бітної, то програма поверне NULL, 

![image](https://github.com/user-attachments/assets/b54ea04d-68a8-49aa-a264-2bec87901ada)

і в цьому випадку це означає, що мені немає чого хвилюватися, і time_t закінчиться не скоро. Навіть якщо time_t може зберігати дуже велике значення, структура struct tm, яка використовується для представлення компонентів часу , може мати власні обмеження щодо діапазону років, які вона може представляти, тому в мене це відображається як NULL. Проте, у ході опрацювання теоретичного матеріалу, я дізналась, що для 64-бітних систем максимальне значення time_t -  4 грудня 292 277 026 596 року.

## Завдання 2
### Умова
Розгляньте сегменти у виконуваному файлі.
1. Скомпілюйте програму &quot;hello world&quot;, запустіть ls -l для
виконуваного файлу, щоб отримати його загальний розмір, і
запустіть size, щоб отримати розміри сегментів всередині нього.
2. Додайте оголошення глобального масиву із 1000 int,
перекомпілюйте й повторіть вимірювання. Зверніть увагу на
відмінності.
3. Тепер додайте початкове значення в оголошення масиву
(пам’ятайте, що C не змушує вас вказувати значення для кожного
елемента масиву в ініціалізаторі). Це перемістить масив із сегмента
BSS у сегмент даних. Повторіть вимірювання. Зверніть увагу на
різницю.
4. Тепер додайте оголошення великого масиву в локальну функцію.
Оголосіть другий великий локальний масив з ініціалізатором.
Повторіть вимірювання. Дані розташовуються всередині функцій,
залишаючись у виконуваному файлі? Яка різниця, якщо масив
ініціалізований чи ні?
5. Які зміни відбуваються з розмірами файлів і сегментів, якщо ви
компілюєте для налагодження? Для максимальної оптимізації?
Проаналізуйте результати, щоб переконатися, що:
● сегмент даних зберігається у виконуваному файлі;
● сегмент BSS не зберігається у виконуваному файлі (за винятком
примітки щодо його вимог до розміру часу виконання);
● текстовий сегмент більшою мірою піддається перевіркам
оптимізації;
● на розмір файлу a.out впливає компіляція для налагодження, але не
сегменти.
### Рішення
Я написала невеликий [код](https://github.com/AnastasiiaVdovina/Practice2/blob/main/task2.c) для проведення вищезгаданих експериментів. Виконуючи команди з першого пункту я отримала такі результати:

![image](https://github.com/user-attachments/assets/2641f986-d9c2-44ae-8e60-92f48da9adcb)

![image](https://github.com/user-attachments/assets/4cd3c884-1ba3-4982-bc9a-aaa1da16b411)

Після виконання пункту 2 і повторення тих самих команд:

![image](https://github.com/user-attachments/assets/175f7cd4-04dd-4f36-b2c3-2f38d7305ddb)

Бачимо, що блок BSS значно збільшився.

Виконуємо пункт 3 та повторюємо вимірювання. Отримаємо:

![image](https://github.com/user-attachments/assets/3210337d-35c9-498a-9dfa-f7a536342515)

Ми перемістили наш масив з блоку BSS у блок Data, і на скріні бачимо, що розміри цих блоків змінились відповідно.

Виконуючи пункт 4, отримуємо такий результат:

![image](https://github.com/user-attachments/assets/b3b4b921-63cc-49c3-9d23-443631fb83c9)

Локальні масиви, незалежно від того, чи вони ініціалізовані, чи ні, зазвичай розміщуються в стеку під час виконання програми, а не в постійних сегментах даних або BSS виконуваного файлу. Різниця між ініціалізованим та неініціалізованим локальним масивом у контексті виконуваного файлу полягає в тому, що дані ініціалізації для ініціалізованого масиву можуть бути присутніми в текстовому сегменті, що призведе до дещо більшого текстового сегмента порівняно з неініціалізованим масивом.
Відповіді на питання пункту 5:
1) Компіляція з прапорцем -g (для налагодження) значно збільшить загальний розмір виконуваного файлу. Це пов'язано з тим, що до нього додається налагоджувальна інформація та інші дані, необхідні налагоджувачам.
2) Компіляція з прапорцями оптимізації зазвичай зменшує розмір текстового сегмента. Оптимізації можуть видалити зайвий код, вбудувати функції та зробити код ефективнішим, і це може призвести до зменшення загального розміру виконуваного файлу.

## Завдання 3
### Умова
Скомпілюйте й запустіть тестову програму, щоб визначити приблизне
розташування стека у вашій системі:
```С
#include <stdio.h>
int main() {
int i;
printf("The stack top is near %p\n", &i);
return 0;
}
```
Знайдіть розташування сегментів даних і тексту, а також купи всередині
сегмента даних, оголосіть змінні, які будуть поміщені в ці сегменти, і
виведіть їхні адреси.
Збільшіть розмір стека, викликавши функцію й оголосивши кілька
великих локальних масивів. Яка зараз адреса вершини стека?
### Рішення
Спочатку я скомпілювала запропонований код, і отримала адресу приблизного розташування стека у своїй системі.

![image](https://github.com/user-attachments/assets/d800d8eb-bd9d-495c-ae9a-f2e6274e8e3e)

Потім я написала [код](https://github.com/AnastasiiaVdovina/Practice2/blob/main/task3.c), в якому оголосила декілька змінних(локальних і глобальних) та функцію. А далі я вивели адреси розташування цих елементів:

![image](https://github.com/user-attachments/assets/47d14ddc-0c80-4f8d-ad04-9d838ca8fbaa)

## Завдання 4
### Умова
Ваше завдання – дослідити стек процесу або пригадати, як це робиться. Ви
можете:
● Автоматично за допомогою утиліти gstack.
● Вручну за допомогою налагоджувача GDB.
### Рішення
Мені не вдалося встановити утиліту gstack, тому довелося користуватися GDB, і робити все вручну. Я використала такий самий pid процесу, як і використовувався у прикладі.

![image](https://github.com/user-attachments/assets/2a04a4cf-9f7e-4543-a1eb-62e6da6a6297)

На момент даного експерименту процес не був запущений, і gdb дав нам про це знати.
Щоб запустити процес, і знову це перевірити, у завданні було надано приклад коду та інструкція, за якою потрібно це зробити. Програма має таки вивід:

![image](https://github.com/user-attachments/assets/a63958d0-c7dd-427a-abc0-f727c233aec6)

Далі треба було через gdb підключитися до pid-процесу, та знову перевірити стек, але на моменті паузи моє віртувльне середовище не подає жодних ознак залізного життя(

## Завдання 5
### Умова
Відомо, що при виклику процедур і поверненні з них процесор
використовує стек.Чи можна в такій схемі обійтися без лічильника команд
(IP), використовуючи замість нього вершину стека? Обґрунтуйте свою
відповідь та наведіть приклади.
### Рішення
На мою думку, обійтися без лічильника команд, використовуючи лише вершину стека, не вийде. Стек потрібен для зберігання адреси повернення з процедури та локальних змінних. Якщо вершина стека буде одночасно вказувати на наступну інструкцію, то виникне плутанина між адресами інструкцій і самими даними на стеку. Крім того, процесору потрібно якось знати, яку інструкцію виконувати далі, а розмір інструкцій може бути різним. Також, як би ми реалізовували переходи всередині процедури, якщо б просто змінювали вершину стека? Це б порушило логіку повернення та керування локальними змінними. Тому, на мою думку, лічильник команд є необхідним для чіткого відстеження, яка інструкція має виконуватися. Хоча в теорії таку архітектуру можна уявити, але вона дуже непрактична.

## Завдання 6(Індивідуальне завдання)
### Умова
Напишіть програму, що визначає максимально можливий розмір
сегмента кучі.
### Рішення
Я написала [код](https://github.com/AnastasiiaVdovina/Practice2/blob/main/ind_task.c), який в досить цікавий спосіб визначає максимальний розмір сегмента кучі. В мене було багато спроб та ідей як це зробити. Спочатку, програма мала запускатися, виділяти пам'ять, зупинятися коли вже не може виділити, і виводити скільки вдалося виділити. Але реалізація цієї ідеї по факту працювала так: запускається програма, проходить 5 хвилин(вона дійсно так довго працювала) і потім вивід "Killed", "Failed to reclaim memory". Далі, щоб бачити все ж таки, що програма виділяє пам'ять, я вирішила загальну логіку залишити незмінною, але при кожній спробі виділити пам'ять додатково записувати це у файл, бо хай би там як програма не завершилася, а файл має залишитись. Цей текстовий файл не прикріплений до репозиторію, бо він має надто великий розмір, чого і варто було очікувати. Але він в мене через це також і не відкривається, або відкривається порожнім. 
Тому наразі, оптимальне рішення, яке я придумала для цієї задачі працює наступним чином:

![image](https://github.com/user-attachments/assets/c52beaa8-c446-42e4-87e2-5c119a52375b)

Логіка залишається тією ж, але всі ітерації виділення пам'яті ми виводимо в консоль. В кінці (очевидно) отримуємо "Killed", але останнє значення, але було виведене перед цією помилкою, по факту і є максимальним розміром сегмента кучі, бо далі ми пам'ять виділити не можемо.
